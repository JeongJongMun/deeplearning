{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward() vs autograd.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class sampleClass(torch.nn.Module):\n",
    "\tdef __init__(self) -> None:\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.linear1 = torch.nn.Linear(3, 4)\n",
    "\t\tself.relu = torch.nn.ReLU()\n",
    "\t\tself.linear2 = torch.nn.Linear(4, 2)\n",
    "\t\tself.ff = torch.nn.Sequential(\n",
    "\t\tself.linear1,\n",
    "\t\tself.relu,\n",
    "\t\tself.linear2\n",
    "\t)\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      " tensor([[ 0.3156,  0.0134, -0.3926],\n",
      "        [ 0.2629, -0.0848, -0.2791]])\n",
      "linear1.weight \n",
      " tensor([[ 1.7027,  2.5381, -0.2534],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0880,  0.3149, -0.2677],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n",
      "\n",
      "linear1.bias \n",
      " tensor([1.9597, 0.0000, 0.2281, 0.0000])\n",
      "\n",
      "linear2.weight \n",
      " tensor([[-1.1070,  0.0000, -0.6943,  0.0000],\n",
      "        [ 1.4367,  0.0000,  0.9439,  0.0000]])\n",
      "\n",
      "linear2.bias \n",
      " tensor([-2.6285,  3.2862])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loss.backward()\n",
    "model = sampleClass()\n",
    "model.train()\n",
    "\n",
    "target = torch.tensor([1., -1.0])\n",
    "\n",
    "input = torch.randn(2,3 , requires_grad=True)\n",
    "output = model(input)\n",
    "loss = torch.square(target-output).mean(dim=-1)\n",
    "loss = torch.sum(loss)\n",
    "loss.backward()\n",
    "\n",
    "# 모델의 Weight와 Bias와 Input들의 grad에 미분 값들이 저장된다.\n",
    "print(\"Input\\n\",input.grad)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, '\\n', param.grad)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.1363, -0.0687, -0.0417],\n",
      "        [ 0.1086, -0.0610, -0.0049]]),)\n",
      "Input\n",
      " None\n",
      "linear1.weight \n",
      " None\n",
      "\n",
      "linear1.bias \n",
      " None\n",
      "\n",
      "linear2.weight \n",
      " None\n",
      "\n",
      "linear2.bias \n",
      " None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.autograd.grad\n",
    "model2 = sampleClass()\n",
    "model2.train()\n",
    "\n",
    "input = torch.randn(2,3 , requires_grad=True)\n",
    "output = model2(input)\n",
    "loss = torch.square(target-output).mean(dim=-1)\n",
    "loss = torch.sum(loss)\n",
    "# input에 대한 loss의 기울기만 반환만 함 (grad에 저장 X)\n",
    "print(torch.autograd.grad(outputs=loss, inputs=input))\n",
    "\n",
    "# 모델의 Weight와 Bias와 Input들의 grad에 미분 값들이 저장되지 않는다.\n",
    "print(\"Input\\n\",input.grad)\n",
    "for name, param in model2.named_parameters():\n",
    "    print(name, '\\n', param.grad)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad() # Reset gradients\n",
    "# for i, (inputs, labels) in enumerate(dataloader):\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward() # Gradients are accumulated\n",
    "    \n",
    "#     if (i + 1) % gradient_accumulation_steps == 0:\n",
    "#         optimizer.step() # Update weights\n",
    "#         optimizer.zero_grad() # Reset gradients for the next iteration\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
